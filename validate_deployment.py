
#!/usr/bin/env python3
"""
Deployment Validation Script
Validates that the export package is ready for deployment
"""

import os
import json
import sys
from pathlib import Path
from datetime import datetime

def find_arkival_paths():
    """
    # @codebase-summary: Universal path resolution for Arkival subdirectory deployment
    - Detects deployment mode and returns all required file paths for validation
    - Used by deployment validation system to locate configuration files
    
    Universal path resolution for Arkival subdirectory deployment
    Returns: Dict with all required paths
    """
    current_dir = Path.cwd()
    project_root = None
    
    # Search upward for arkival.config.json
    search_path = current_dir
    for _ in range(5):  # Max 5 levels up
        if (search_path / "arkival.config.json").exists():
            project_root = search_path
            break
        if search_path.parent == search_path:  # Reached filesystem root
            break
        search_path = search_path.parent
    
    # Try alternative detection methods
    if not project_root:
        # Look for Arkival directory as indicator
        search_path = current_dir
        for _ in range(5):
            if (search_path / "Arkival").exists():
                project_root = search_path
                break
            search_path = search_path.parent
    
    # Fallback - assume current directory
    if not project_root:
        project_root = current_dir
    
    # Determine if we're in dev mode or subdirectory mode
    # Dev mode: scripts are in codebase_summary/, data files in root
    # Subdirectory mode: everything under Arkival/
    
    if current_dir.name.lower() in ['arkival', 'arkival-v4'] or (project_root / "arkival_config.json").exists():
        # Subdirectory deployment mode
        arkival_dir = project_root / "Arkival"
        return {
            'project_root': project_root,
            'config_file': project_root / "arkival_config.json",
            'arkival_dir': arkival_dir,
            'data_dir': arkival_dir,  # Same as arkival_dir, no separate data folder
            'scripts_dir': arkival_dir / "codebase_summary", 
            'export_dir': arkival_dir / "export_package",
            'checkpoints_dir': arkival_dir / "checkpoints",
            'validation_root': arkival_dir,
            'manifest_file': arkival_dir / "EXPORT_PACKAGE_MANIFEST.json",
            
            # Data files in arkival root, matching dev mode structure
            'codebase_summary': arkival_dir / "codebase_summary.json",
            'changelog_summary': arkival_dir / "changelog_summary.json",
            'session_state': arkival_dir / "codebase_summary" / "session_state.json",
            'missing_breadcrumbs': arkival_dir / "codebase_summary" / "missing_breadcrumbs.json"
        }
    else:
        # Development mode - use root directory structure
        return {
            'project_root': project_root,
            'config_file': project_root / "arkival_config.json",
            'arkival_dir': project_root,
            'data_dir': project_root,
            'scripts_dir': project_root / "codebase_summary", 
            'export_dir': project_root / "export_package",
            'checkpoints_dir': project_root / "checkpoints",
            'validation_root': project_root,
            'manifest_file': project_root / "EXPORT_PACKAGE_MANIFEST.json",
            
            # Data files in root/standard locations
            'codebase_summary': project_root / "codebase_summary.json",
            'changelog_summary': project_root / "changelog_summary.json",
            'session_state': project_root / "codebase_summary" / "session_state.json",
            'missing_breadcrumbs': project_root / "codebase_summary" / "missing_breadcrumbs.json"
        }

def validate_against_manifest():
    """
    # @codebase-summary: Validates deployment against EXPORT_PACKAGE_MANIFEST.json specifications
    - Loads and validates manifest file structure
    - Checks all required files specified in manifest exist
    - Verifies quality metrics meet manifest standards
    - Ensures deployment architecture compliance
    - Returns validation status and detailed results
    """
    print("üìã VALIDATING AGAINST EXPORT PACKAGE MANIFEST")
    print("=" * 50)
    
    paths = find_arkival_paths()
    manifest_file = paths['manifest_file']
    validation_root = paths['validation_root']
    
    try:
        with open(manifest_file, 'r') as f:
            manifest = json.load(f)
        print(f"‚úÖ Loaded manifest: {manifest['package_name']} v{manifest['version']}")
    except FileNotFoundError:
        print("‚ö†Ô∏è  EXPORT_PACKAGE_MANIFEST.json not found - skipping manifest validation")
        return True
    except json.JSONDecodeError as e:
        print(f"‚ùå Invalid manifest JSON: {e}")
        return False
    
    # Validate all required file categories
    all_files_valid = True
    total_required = 0
    found_files = 0
    
    for category, files in manifest.get("required_files", {}).items():
        print(f"\nüìÅ Checking {category}:")
        for file_path in files:
            total_required += 1
            full_path = validation_root / file_path
            if full_path.exists():
                print(f"  ‚úÖ {file_path}")
                found_files += 1
            else:
                print(f"  ‚ùå {file_path} - MISSING")
                all_files_valid = False
    
    print(f"\nüìä Manifest Validation Results:")
    print(f"   Required Files: {found_files}/{total_required} found")
    print(f"   Status: {manifest.get('status', 'UNKNOWN')}")
    print(f"   Confidence: {manifest.get('confidence_level', 'UNKNOWN')}")
    
    return all_files_valid

def validate_export_package():
    """
    # @codebase-summary: Core deployment validation system for export package
    - Validates all required files exist and are properly configured
    - Checks JSON configuration files for syntax and completeness
    - Verifies workflow system setup and dependencies
    - Validates against EXPORT_PACKAGE_MANIFEST.json specifications
    - Generates deployment readiness report
    - Used by: deployment automation, quality assurance, release preparation
    """
    print("üîç EXPORT PACKAGE DEPLOYMENT VALIDATION")
    print("=" * 50)
    
    paths = find_arkival_paths()
    validation_root = paths['validation_root']
    
    # Core required files for Arkival functionality
    core_required_files = [
        "setup_workflow_system.py",
        "workflow_config.json", 
        "changelog_summary.json",
        "codebase_summary/agent_workflow_orchestrator.py",
        "codebase_summary/update_changelog.py",
        "codebase_summary/update_project_summary.py"
    ]
    
    # Optional documentation files (not required for existing projects)
    optional_docs = [
        "AGENT_GUIDE.md",
        "CONTRIBUTING.md",
        "README.md"
    ]
    
    # Check if this is an existing project integration
    is_existing_project = (
        (validation_root.parent / "package.json").exists() or
        (validation_root.parent / "src").exists() or
        (validation_root.parent / "app").exists() or
        validation_root.name.lower() == "arkival"
    )
    
    # For existing projects, only check core files
    required_files = core_required_files if is_existing_project else core_required_files + optional_docs
    
    print("üìÅ Checking required files...")
    missing_files = []
    for file_path in required_files:
        full_path = validation_root / file_path
        if full_path.exists():
            print(f"‚úÖ {file_path}")
        else:
            print(f"‚ùå {file_path} - MISSING")
            missing_files.append(file_path)
    
    if missing_files:
        print(f"\n‚ùå {len(missing_files)} required files are missing!")
        return False
    
    print("\nüìã Validating JSON configuration files...")
    json_files = ["workflow_config.json", "changelog_summary.json"]
    for json_file in json_files:
        try:
            full_path = validation_root / json_file
            with open(full_path, 'r') as f:
                data = json.load(f)
            print(f"‚úÖ {json_file} - Valid JSON")
        except json.JSONDecodeError as e:
            print(f"‚ùå {json_file} - Invalid JSON: {e}")
            return False
    
    print("\nüîß Checking configuration completeness...")
    with open("workflow_config.json", 'r') as f:
        config = json.load(f)
        
        issues = []
        if "NEEDS_CONFIGURATION" in config.get("technology_stack", []):
            issues.append("Technology stack needs AI agent configuration")
        if config.get("project_name") == "New Project":
            issues.append("Project name needs customization")
        if not config.get("project_specific", {}).get("main_files"):
            issues.append("Main files list is empty")
            
        if issues:
            print("‚ö†Ô∏è  Configuration warnings:")
            for issue in issues:
                print(f"   - {issue}")
            print("   ‚Üí These will be resolved during project analysis")
        else:
            print("‚úÖ Configuration is complete")
    
    print("\nüéØ Checking Python script executability...")
    python_scripts = [
        "setup_workflow_system.py",
        "codebase_summary/agent_workflow_orchestrator.py",
        "codebase_summary/update_changelog.py"
    ]
    
    for script in python_scripts:
        if Path(script).exists():
            print(f"‚úÖ {script} - Ready for execution")
        else:
            print(f"‚ùå {script} - Missing")
            return False
    
    print("\nüßπ Checking for post-deployment cleanup requirements...")
    cleanup_dirs = [
        "codebase_summary/language_scan_tests/",
        "codebase_summary/history/"
    ]
    
    cleanup_needed = []
    for cleanup_dir in cleanup_dirs:
        if Path(cleanup_dir).exists():
            file_count = len(list(Path(cleanup_dir).glob("*")))
            if file_count > 0:
                cleanup_needed.append(f"{cleanup_dir} ({file_count} files)")
    
    if cleanup_needed:
        print("‚ö†Ô∏è  Post-deployment cleanup recommended:")
        for item in cleanup_needed:
            print(f"   - {item}")
        print("   ‚Üí Run post-deployment cleanup to optimize performance")
    else:
        print("‚úÖ No cleanup required")
    
    # Validate against manifest specifications
    print("\n" + "="*50)
    manifest_valid = validate_against_manifest()
    
    if not manifest_valid:
        print("\n‚ùå MANIFEST VALIDATION FAILED")
        return False
    
    print("\n‚úÖ EXPORT PACKAGE VALIDATION PASSED")
    print("üöÄ Ready for deployment to new projects")
    return True

def cleanup_post_deployment():
    """
    # @codebase-summary: Post-deployment cleanup for prompt caching optimization
    - Adds test files to .scanignore and archives excessive history after successful deployment
    - Optimizes prompt caching by reducing context size (~5000 tokens)
    - Preserves test files for debugging while excluding them from scans
    - Used by: deployment automation, performance optimization
    """
    print("üßπ POST-DEPLOYMENT CLEANUP")
    print("=" * 40)
    
    # Check if this is the source repository (has development marker files)
    is_source_repo = (
        Path("EXPORT_PACKAGE_MANIFEST.json").exists() or
        Path(".github").exists() or
        Path("reference_assets").exists()
    )
    
    if is_source_repo:
        print("üîç DETECTED SOURCE REPOSITORY - SIMULATION MODE")
        print("   ‚Üí Cleanup actions will be simulated, not executed")
        print("   ‚Üí This preserves development files in the main repo")
        print("")
    
    cleanup_actions = []
    
    # Add language scan test files to .scanignore (don't delete them)
    test_dir = Path("codebase_summary/language_scan_tests/")
    if test_dir.exists():
        test_files = list(test_dir.glob("*"))
        if test_files:
            try:
                scanignore_path = Path(".scanignore")
                pattern_to_add = "codebase_summary/language_scan_tests/"
                
                # Check if pattern already exists
                pattern_exists = False
                if scanignore_path.exists():
                    with open(scanignore_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if pattern_to_add in content:
                            pattern_exists = True
                
                if not pattern_exists:
                    # Add pattern to .scanignore
                    with open(scanignore_path, 'a', encoding='utf-8') as f:
                        f.write(f"\n# Added by post-deployment cleanup\n{pattern_to_add}\n")
                    
                    if is_source_repo:
                        print(f"üé≠ SIMULATION: Would add {len(test_files)} language test files to .scanignore")
                        cleanup_actions.append(f"SIMULATED: Would add language_scan_tests/ to .scanignore")
                    else:
                        print(f"‚úÖ Added language_scan_tests/ to .scanignore ({len(test_files)} test files preserved)")
                        cleanup_actions.append(f"Added language_scan_tests/ to .scanignore")
                else:
                    print(f"‚úÖ language_scan_tests/ already in .scanignore")
            except Exception as e:
                print(f"‚ö†Ô∏è  Could not update .scanignore: {e}")
                # Don't fail the entire cleanup if this fails
    
    # Keep only last 5 history files (with verification)
    history_dir = Path("codebase_summary/history/")
    if history_dir.exists():
        history_files = sorted(history_dir.glob("*.json"))
        if len(history_files) > 5:
            files_to_remove = history_files[:-5]
            try:
                # Verify files exist before attempting removal
                existing_files_to_remove = [f for f in files_to_remove if f.exists()]
                
                if is_source_repo:
                    # Simulation mode - don't actually delete
                    print(f"üé≠ SIMULATION: Would archive {len(existing_files_to_remove)} old history files")
                    cleanup_actions.append(f"SIMULATED: Would archive {len(existing_files_to_remove)} old history files")
                else:
                    # Production mode - actually delete files
                    for old_file in existing_files_to_remove:
                        # Additional safety check
                        if old_file.is_file() and old_file.suffix == '.json':
                            old_file.unlink()
                    
                    if existing_files_to_remove:
                        cleanup_actions.append(f"Archived {len(existing_files_to_remove)} old history files")
            except Exception as e:
                print(f"‚ö†Ô∏è  Could not archive history files: {e}")
                # Continue with other cleanup operations
    
    if cleanup_actions:
        print("‚úÖ Cleanup completed:")
        for action in cleanup_actions:
            print(f"   - {action}")
        print(f"\nüí° Estimated performance improvement: ~{len(cleanup_actions) * 25}% faster loading")
    else:
        print("‚úÖ No cleanup needed - system already optimized")
    
    return len(cleanup_actions) > 0

def main():
    """
    # @codebase-summary: Main validation execution entry point
    - Coordinates complete deployment validation process
    - Provides console output and exit codes for automation
    - Handles validation errors with proper error reporting
    - Supports post-deployment cleanup mode
    """
    if len(sys.argv) > 1 and sys.argv[1] == "cleanup":
        cleanup_post_deployment()
        return
    
    print(f"Validation started at: {datetime.now().isoformat()}")
    
    try:
        if validate_export_package():
            print("\nüéâ DEPLOYMENT VALIDATION SUCCESSFUL")
            print("The export package is ready for deployment to new projects.")
            print("\nüí° TIP: After successful deployment, run:")
            print("   python3 validate_deployment.py cleanup")
            print("   ‚Üí This will optimize system performance")
            sys.exit(0)
        else:
            print("\n‚ùå DEPLOYMENT VALIDATION FAILED")
            print("Please fix the issues above before deploying.")
            sys.exit(1)
    except Exception as e:
        print(f"\nüí• Validation error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
